{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from threading import Thread\n",
    "from pprint import pprint as pp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33530 entries, 0 to 33529\n",
      "Data columns (total 13 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Execution                      33530 non-null  int64  \n",
      " 1   ScenarioID                     33530 non-null  object \n",
      " 2   Configuration_API_Description  33530 non-null  object \n",
      " 3   Attribute[TTC]                 33530 non-null  float64\n",
      " 4   Attribute[DTO]                 33530 non-null  float64\n",
      " 5   Attribute[Jerk]                33530 non-null  float64\n",
      " 6   Attribute[COL]                 33530 non-null  bool   \n",
      " 7   Attribute[COLT]                33530 non-null  object \n",
      " 8   Attribute[SAC]                 33530 non-null  float64\n",
      " 9   reward                         33530 non-null  object \n",
      " 10  road                           33530 non-null  object \n",
      " 11  strategy                       33530 non-null  object \n",
      " 12  scenario                       33530 non-null  object \n",
      "dtypes: bool(1), float64(4), int64(1), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/deep-scenario.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManipulation():\n",
    "    def __init__(self, filename: str=\"\"):\n",
    "        self.data = filename\n",
    "\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, filename: str=\"\"):\n",
    "        try:\n",
    "            self._data = pd.read_csv(filename)\n",
    "        except:\n",
    "            self._data = None\n",
    "            raise FileNotFoundError(f\"The file does not exist.\")\n",
    "\n",
    "\n",
    "    def addFromXML(self, filename: str=\"\") -> None:\n",
    "        \"\"\"\n",
    "        Reads more data from XML files, as of now, only speeds at six different timstamps.\n",
    "\n",
    "        Params:\n",
    "            filename: str, name of file read from\n",
    "        \"\"\"\n",
    "        try:\n",
    "            xmlDf = pd.read_csv(filename, index_col=0)\n",
    "        except:\n",
    "            raise FileNotFoundError(f\"The file does not exist.\")\n",
    "        if isinstance(self.data, pd.DataFrame):\n",
    "            self._data = self.data.merge(xmlDf, how=\"inner\", on=[\"ScenarioID\", \"road\", \"reward\", \"scenario\", \"strategy\"], copy=False)\n",
    "        else:\n",
    "            print(\"Something went wrong in 'addFromXML()'!\")\n",
    "\n",
    "\n",
    "    def splitTrainTest(self, splitRatio: float=0.8) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Splitting the data.\n",
    "\n",
    "        Params:\n",
    "            filename: str, name of file to split\n",
    "            splitRatio: float 0-1, % of data to be testing\n",
    "\n",
    "        TODO\n",
    "            Sl√• sammen road, scenario, strategy og reward til noe brukbart\n",
    "\n",
    "        Returns:\n",
    "            trainX, trainY, testingX, testingY.\n",
    "        \"\"\"\n",
    "        if not 0 < splitRatio < 1: raise ValueError(\"SplitRatio must be between 0 and 1!\")\n",
    "\n",
    "        # Shuffle data\n",
    "        self._data = self.data.sample(frac=1, random_state=1)\n",
    "\n",
    "        temp = self._data.copy()\n",
    "        # Removing all non numeric values, might need to make string values into numbers\n",
    "        temp = temp.drop([\"Execution\",\"ScenarioID\",\"Configuration_API_Description\"], axis=1)\n",
    "        split = int(np.floor(len(self.data)*splitRatio))\n",
    "        print(f\"splitting at {split}.\")\n",
    "\n",
    "        trainX, testX = temp[:split], temp[split:]\n",
    "\n",
    "        trainY = pd.concat([trainX.pop(feature) for feature in [\"Attribute[COL]\",\"Attribute[COLT]\",\"Attribute[SAC]\"]], axis=1)\n",
    "        testY = pd.concat([testX.pop(feature) for feature in [\"Attribute[COL]\",\"Attribute[COLT]\",\"Attribute[SAC]\"]], axis=1)\n",
    "\n",
    "        return trainX, trainY, testX, testY\n",
    "\n",
    "\n",
    "    def getCompleteRow(self, index: None):\n",
    "        \"\"\"\n",
    "        Gets the origianl row from index(es).\n",
    "\n",
    "        Params:\n",
    "            index: int or list\n",
    "\n",
    "        Return:\n",
    "            Dataframe or Series\n",
    "        \"\"\"\n",
    "        if isinstance(index, list) or isinstance(index, int):\n",
    "            return self._data.loc[index]\n",
    "        return \"Something went wrong.\"\n",
    "\n",
    "\n",
    "    def getOriginalPath(self, index: int):\n",
    "        \"\"\"\n",
    "        Gets the complete path from where the row was originally collected together with its ScenarioID.\n",
    "\n",
    "        Params:\n",
    "            index: int\n",
    "\n",
    "        Return:\n",
    "            dict{\"SenarioID\": str, \"path\": str}\n",
    "        \"\"\"\n",
    "        if isinstance(index, int):\n",
    "            row = self.getCompleteRow(index)\n",
    "            return {\n",
    "                \"ScenarioID\": row[\"ScenarioID\"],\n",
    "                \"path\": f\"{row['strategy']}-strategy/reward-{row['reward']}/{row['road']}-{row['scenario']}-scenario-attributes.csv\"\n",
    "                }\n",
    "        raise ValueError(\"Index needs to be an integer!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting at 26824.\n",
      "0.0\n",
      "trainX:(26824, 13), trainY:(26824, 3), testX:(6706, 13), testY:(6706, 3)\n",
      "       Attribute[TTC]  Attribute[DTO]  Attribute[Jerk] reward   road  \\\n",
      "23853   100000.000000        6.434714             5.04    ttc  road2   \n",
      "30032        0.695324        5.552715             5.74   jerk  road2   \n",
      "11507   100000.000000        8.511993             5.90    ttc  road3   \n",
      "17653        0.760641        7.845926            14.30    dto  road4   \n",
      "16680        8.738029       14.960495             0.88    dto  road3   \n",
      "\n",
      "       strategy     scenario  speed1  speed2  speed3  speed4  speed5  speed6  \n",
      "23853    random   rain_night   5.547   4.660   4.401   4.228   3.986   3.746  \n",
      "30032  rl_based  sunny_night   5.558   4.607   4.358   4.832   4.246   3.967  \n",
      "11507    greedy   rain_night   0.908   0.001   0.789   0.687   0.001   1.000  \n",
      "17653    random  sunny_night   5.127   6.324   6.615   8.165   8.313   8.683  \n",
      "16680    random  sunny_night   8.075   8.280   8.360   8.458   8.566   8.755  \n",
      "Attribute[COL]  False  True \n",
      "strategy                    \n",
      "greedy          10440    147\n",
      "random          10736    129\n",
      "rl_based         4813    559\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute[TTC]</th>\n",
       "      <th>Attribute[DTO]</th>\n",
       "      <th>Attribute[Jerk]</th>\n",
       "      <th>speed1</th>\n",
       "      <th>speed2</th>\n",
       "      <th>speed3</th>\n",
       "      <th>speed4</th>\n",
       "      <th>speed5</th>\n",
       "      <th>speed6</th>\n",
       "      <th>Attribute[COL]</th>\n",
       "      <th>Attribute[SAC]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attribute[TTC]</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100788</td>\n",
       "      <td>-0.144095</td>\n",
       "      <td>-0.253022</td>\n",
       "      <td>-0.240292</td>\n",
       "      <td>-0.193335</td>\n",
       "      <td>-0.147007</td>\n",
       "      <td>-0.108904</td>\n",
       "      <td>-0.084859</td>\n",
       "      <td>-0.047727</td>\n",
       "      <td>-0.048451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute[DTO]</th>\n",
       "      <td>0.100788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036130</td>\n",
       "      <td>-0.079110</td>\n",
       "      <td>-0.064905</td>\n",
       "      <td>-0.033969</td>\n",
       "      <td>-0.004660</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>-0.011135</td>\n",
       "      <td>-0.008658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute[Jerk]</th>\n",
       "      <td>-0.144095</td>\n",
       "      <td>-0.036130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.220794</td>\n",
       "      <td>0.207929</td>\n",
       "      <td>0.138693</td>\n",
       "      <td>0.079876</td>\n",
       "      <td>0.040943</td>\n",
       "      <td>0.017524</td>\n",
       "      <td>0.099308</td>\n",
       "      <td>0.095497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed1</th>\n",
       "      <td>-0.253022</td>\n",
       "      <td>-0.079110</td>\n",
       "      <td>0.220794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.873227</td>\n",
       "      <td>0.747700</td>\n",
       "      <td>0.635589</td>\n",
       "      <td>0.548470</td>\n",
       "      <td>0.113364</td>\n",
       "      <td>0.108645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed2</th>\n",
       "      <td>-0.240292</td>\n",
       "      <td>-0.064905</td>\n",
       "      <td>0.207929</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930704</td>\n",
       "      <td>0.817816</td>\n",
       "      <td>0.714630</td>\n",
       "      <td>0.633528</td>\n",
       "      <td>0.093444</td>\n",
       "      <td>0.090953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed3</th>\n",
       "      <td>-0.193335</td>\n",
       "      <td>-0.033969</td>\n",
       "      <td>0.138693</td>\n",
       "      <td>0.873227</td>\n",
       "      <td>0.930704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935293</td>\n",
       "      <td>0.853828</td>\n",
       "      <td>0.778939</td>\n",
       "      <td>0.033763</td>\n",
       "      <td>0.077092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed4</th>\n",
       "      <td>-0.147007</td>\n",
       "      <td>-0.004660</td>\n",
       "      <td>0.079876</td>\n",
       "      <td>0.747700</td>\n",
       "      <td>0.817816</td>\n",
       "      <td>0.935293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950989</td>\n",
       "      <td>0.888524</td>\n",
       "      <td>-0.041214</td>\n",
       "      <td>0.052189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed5</th>\n",
       "      <td>-0.108904</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.040943</td>\n",
       "      <td>0.635589</td>\n",
       "      <td>0.714630</td>\n",
       "      <td>0.853828</td>\n",
       "      <td>0.950989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960588</td>\n",
       "      <td>-0.101034</td>\n",
       "      <td>0.006146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speed6</th>\n",
       "      <td>-0.084859</td>\n",
       "      <td>0.032633</td>\n",
       "      <td>0.017524</td>\n",
       "      <td>0.548470</td>\n",
       "      <td>0.633528</td>\n",
       "      <td>0.778939</td>\n",
       "      <td>0.888524</td>\n",
       "      <td>0.960588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.132265</td>\n",
       "      <td>-0.024836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute[COL]</th>\n",
       "      <td>-0.047727</td>\n",
       "      <td>-0.011135</td>\n",
       "      <td>0.099308</td>\n",
       "      <td>0.113364</td>\n",
       "      <td>0.093444</td>\n",
       "      <td>0.033763</td>\n",
       "      <td>-0.041214</td>\n",
       "      <td>-0.101034</td>\n",
       "      <td>-0.132265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attribute[SAC]</th>\n",
       "      <td>-0.048451</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>0.095497</td>\n",
       "      <td>0.108645</td>\n",
       "      <td>0.090953</td>\n",
       "      <td>0.077092</td>\n",
       "      <td>0.052189</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>-0.024836</td>\n",
       "      <td>0.776937</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Attribute[TTC]  Attribute[DTO]  Attribute[Jerk]    speed1  \\\n",
       "Attribute[TTC]         1.000000        0.100788        -0.144095 -0.253022   \n",
       "Attribute[DTO]         0.100788        1.000000        -0.036130 -0.079110   \n",
       "Attribute[Jerk]       -0.144095       -0.036130         1.000000  0.220794   \n",
       "speed1                -0.253022       -0.079110         0.220794  1.000000   \n",
       "speed2                -0.240292       -0.064905         0.207929  0.965072   \n",
       "speed3                -0.193335       -0.033969         0.138693  0.873227   \n",
       "speed4                -0.147007       -0.004660         0.079876  0.747700   \n",
       "speed5                -0.108904        0.017686         0.040943  0.635589   \n",
       "speed6                -0.084859        0.032633         0.017524  0.548470   \n",
       "Attribute[COL]        -0.047727       -0.011135         0.099308  0.113364   \n",
       "Attribute[SAC]        -0.048451       -0.008658         0.095497  0.108645   \n",
       "\n",
       "                   speed2    speed3    speed4    speed5    speed6  \\\n",
       "Attribute[TTC]  -0.240292 -0.193335 -0.147007 -0.108904 -0.084859   \n",
       "Attribute[DTO]  -0.064905 -0.033969 -0.004660  0.017686  0.032633   \n",
       "Attribute[Jerk]  0.207929  0.138693  0.079876  0.040943  0.017524   \n",
       "speed1           0.965072  0.873227  0.747700  0.635589  0.548470   \n",
       "speed2           1.000000  0.930704  0.817816  0.714630  0.633528   \n",
       "speed3           0.930704  1.000000  0.935293  0.853828  0.778939   \n",
       "speed4           0.817816  0.935293  1.000000  0.950989  0.888524   \n",
       "speed5           0.714630  0.853828  0.950989  1.000000  0.960588   \n",
       "speed6           0.633528  0.778939  0.888524  0.960588  1.000000   \n",
       "Attribute[COL]   0.093444  0.033763 -0.041214 -0.101034 -0.132265   \n",
       "Attribute[SAC]   0.090953  0.077092  0.052189  0.006146 -0.024836   \n",
       "\n",
       "                 Attribute[COL]  Attribute[SAC]  \n",
       "Attribute[TTC]        -0.047727       -0.048451  \n",
       "Attribute[DTO]        -0.011135       -0.008658  \n",
       "Attribute[Jerk]        0.099308        0.095497  \n",
       "speed1                 0.113364        0.108645  \n",
       "speed2                 0.093444        0.090953  \n",
       "speed3                 0.033763        0.077092  \n",
       "speed4                -0.041214        0.052189  \n",
       "speed5                -0.101034        0.006146  \n",
       "speed6                -0.132265       -0.024836  \n",
       "Attribute[COL]         1.000000        0.776937  \n",
       "Attribute[SAC]         0.776937        1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = DataManipulation(\"../data/deep-scenario.csv\")\n",
    "# dm.data = (\"../data/deep-scenario.csv\")\n",
    "dm.addFromXML(\"../data/dataFromXML.csv\")\n",
    "\n",
    "# print(min(dm.data[\"speed3\"]))\n",
    "\n",
    "trainX, trainY, testX, testY = dm.splitTrainTest()\n",
    "print(min(trainX[\"speed3\"]))\n",
    "print(f\"trainX:{trainX.shape}, trainY:{trainY.shape}, testX:{testX.shape}, testY:{testY.shape}\")\n",
    "print(trainX.head())\n",
    "# trainX.hist(bins=500, figsize=(20,15))\n",
    "max(trainX[\"Attribute[DTO]\"])\n",
    "\n",
    "d = pd.concat([trainX, trainY], axis=1)\n",
    "df = d.groupby(['strategy', 'Attribute[COL]']).size()\n",
    "df = df.unstack()\n",
    "# Very few collisions \n",
    "print(df)\n",
    "d.corr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicter():\n",
    "    \"\"\"\n",
    "    NOTE: Should try other models and should do something about TTC, some are < 15, many are 100000.\n",
    "    \"\"\"\n",
    "    def __init__(self, solver: str=\"adam\", learning_rate: str=\"constant\", activation: str= \"relu\"):\n",
    "        self.model = MLPClassifier(random_state=1, solver=solver, activation=activation, learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "    def preProcess(self, x=None, y=None, targetCol=\"Attribute[COL]\"):\n",
    "        \"\"\"\n",
    "        Process x and y by transforming to np.array and mean scale x.\n",
    "        \n",
    "        Params:\n",
    "            x: dataframe\n",
    "            y: dataframe\n",
    "            targetCol: str, name of column that is to be predicted\n",
    "        \n",
    "        Returns:\n",
    "            x: np.array\n",
    "            y: np.array\n",
    "        \"\"\"\n",
    "        if isinstance(x, pd.DataFrame):\n",
    "            # only accepts numeric values in training as of now\n",
    "            for c in x.columns:\n",
    "                if x[c].dtype != float:\n",
    "                    x = x.drop(c, axis=1)\n",
    "            x.loc[x[\"Attribute[TTC]\"] > 20, \"Attribute[TTC]\"] = -1 # NOTE May be transformed to something else\n",
    "            x.loc[x[\"Attribute[DTO]\"] > 20, \"Attribute[DTO]\"] = -1\n",
    "            # print(x.columns)\n",
    "            x = x.to_numpy()\n",
    "            scaler = preprocessing.StandardScaler().fit(x) # Scaling the input\n",
    "            x = scaler.transform(x)\n",
    "\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            if targetCol and targetCol in y.columns:\n",
    "                y = y[targetCol]\n",
    "                y.replace(False, 0, inplace=True)\n",
    "                y.replace(True, 1, inplace=True)\n",
    "                y = y.to_numpy()\n",
    "            else:\n",
    "                print(\"Wrong parameters was sent in!\")\n",
    "        \n",
    "        return x, y\n",
    "        \n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "\n",
    "        Params:\n",
    "            x: np.array, preprocessed training data\n",
    "            y: np.array, preprocessed training truth\n",
    "        \"\"\"\n",
    "        self.model.fit(x, y)\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Get predictins from the model.\n",
    "\n",
    "        Params:\n",
    "            x: Dataframe, what to predict\n",
    "\n",
    "        Returns:\n",
    "            predictions: np.array of 0 and 1\n",
    "        \"\"\"\n",
    "        return self.model.predict(x)\n",
    "\n",
    "\n",
    "    def getCM(self, predictions, truth):\n",
    "        \"\"\"\"\n",
    "        Shows the score of given predictions and ground truth in a confusion matrix.\n",
    "        \n",
    "        Prints as follows:\n",
    "            True negative | False positive\n",
    "\n",
    "            False negative | True positive\n",
    "\n",
    "        Params:\n",
    "            predictions: np.array\n",
    "            truth: np.array\n",
    "        \n",
    "        Returns:\n",
    "            cm: list[list]\n",
    "        \"\"\"\n",
    "        _, truthProcessed = self.preProcess(y=truth)\n",
    "        tot = 0\n",
    "        cm = [[0, 0], [0, 0]]\n",
    "        # col = np.count_nonzero(truthProcessed == 1)\n",
    "        # print(f\"Total: {tot}, number of collisions: {col}\")\n",
    "        \n",
    "        for p, t in zip(predictions, truthProcessed):\n",
    "            cm[t][p] += 1\n",
    "            tot += 1\n",
    "        \n",
    "        return cm\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def printScore(cm: list[list], modelInfo: list=None, printing: bool=True) -> dict:\n",
    "        \"\"\"\n",
    "        Prints and returns different scoring metrics.\n",
    "\n",
    "        Params:\n",
    "            cm: list[list], 2x2 cononfusion matrix\n",
    "            modelInfo: list, [solver, activation, learning_rate], variables for the model\n",
    "            printing: bool, to print or not\n",
    "\n",
    "        Returns:\n",
    "            dict: accuracy, precision, recall, F1\n",
    "        \"\"\"\n",
    "        def calc(top, bot):\n",
    "            if bot == 0:\n",
    "                return 0\n",
    "            else:\n",
    "                return top/bot\n",
    "        s = {}\n",
    "        s[\"accuracy\"] = round(calc(cm[0][0]+cm[1][1], cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1]), 2)\n",
    "        s[\"precision\"] = round(calc(cm[1][1], cm[0][1]+cm[1][1]), 2)\n",
    "        s[\"recall\"] = round(calc(cm[1][1], cm[1][1]+cm[1][0]), 2)\n",
    "        s[\"f1\"] = round(calc(2*s[\"precision\"]*s[\"recall\"], s[\"precision\"]+s[\"recall\"]), 2)\n",
    "        if printing:\n",
    "            if modelInfo:\n",
    "                print(f\"\\nSolver: {modelInfo[0]}, activation: {modelInfo[1]}, learning rate: {modelInfo[2]}\")\n",
    "            print(f\"\\tTN: {cm[0][0]} \\t| FP: {cm[0][1]} \\n\\tFN: {cm[1][0]} \\t| TP: {cm[1][1]}\")\n",
    "            print(f\"Accuracy: {s['accuracy']}\")\n",
    "            print(f\"Precision: {s['precision']}\")\n",
    "            print(f\"Recall: {s['recall']}\")\n",
    "            print(f\"F1: {s['f1']}\")\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTN: 6475 \t| FP: 16 \n",
      "\tFN: 103 \t| TP: 112\n",
      "Accuracy: 0.98\n",
      "Precision: 0.88\n",
      "Recall: 0.52\n",
      "F1: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.98, 'precision': 0.88, 'recall': 0.52, 'f1': 0.65}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Predicter()\n",
    "\n",
    "x, y = p.preProcess(trainX, trainY)\n",
    "p.fit(x, y)\n",
    "\n",
    "testXp, testYp = p.preProcess(testX, testY)\n",
    "pred = p.predict(testXp)\n",
    "cm = p.getCM(pred, testYp)\n",
    "p.printScore(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def his(column, name):\n",
    "    plt.hist(column, bins=100)\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "\n",
    "names = ['Attribute[TTC]', 'Attribute[DTO]', 'Attribute[Jerk]', 'speed1', 'speed2', 'speed3', 'speed4', 'speed5', 'speed6']\n",
    "# for i in range(len(x[0,:])):\n",
    "#     print(names[i], min(x[:,i]), max(x[:,i]))\n",
    "#     his(x[:,i], names[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with thread 1. Used: 4.2575 seconds.\n",
      "Done with thread 2. Used: 4.5925 seconds.\n",
      "Done with thread 3. Used: 4.5995 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with thread 4. Used: 60.7025 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with thread 5. Used: 61.4725 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with thread 6. Used: 61.7535 seconds.\n",
      "Done with thread 7. Used: 61.7555 seconds.\n",
      "Done with thread 8. Used: 61.7615 seconds.\n",
      "Done with thread 9. Used: 61.9225 seconds.\n",
      "Done with thread 10. Used: 61.9275 seconds.\n",
      "Done with thread 11. Used: 61.9295 seconds.\n",
      "Done with thread 12. Used: 61.9305 seconds.\n",
      "Done with thread 13. Used: 99.1229 seconds.\n",
      "Done with thread 14. Used: 117.6812 seconds.\n",
      "Done with thread 15. Used: 154.5839 seconds.\n",
      "Done with thread 16. Used: 241.5757 seconds.\n",
      "Done with thread 17. Used: 241.5797 seconds.\n",
      "Done with thread 18. Used: 291.4583 seconds.\n",
      "Done with thread 19. Used: 291.4613 seconds.\n",
      "Done with thread 20. Used: 291.4613 seconds.\n",
      "Done with thread 21. Used: 291.4613 seconds.\n",
      "Done with thread 22. Used: 291.4643 seconds.\n",
      "Done with thread 23. Used: 291.4643 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with thread 24. Used: 295.01 seconds.\n",
      "Done with thread 25. Used: 295.01 seconds.\n",
      "Done with thread 26. Used: 295.01 seconds.\n",
      "Done with thread 27. Used: 295.01 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with thread 28. Used: 318.46 seconds.\n",
      "Done with thread 29. Used: 318.56 seconds.\n",
      "Done with thread 30. Used: 318.56 seconds.\n",
      "Done with thread 31. Used: 318.56 seconds.\n",
      "Done with thread 32. Used: 318.56 seconds.\n",
      "Done with thread 33. Used: 318.56 seconds.\n",
      "Done with thread 34. Used: 318.56 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sigurd\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with thread 35. Used: 318.816 seconds.\n",
      "Done with thread 36. Used: 318.816 seconds.\n"
     ]
    }
   ],
   "source": [
    "solver = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "activation = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "learning_rate = [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "\n",
    "modelList = []\n",
    "\n",
    "def useModel(s, l, a):\n",
    "    m = Predicter(s, l, a)\n",
    "    m.fit(x, y)\n",
    "    pred = m.predict(testXp)\n",
    "    # print(f\"\\nSolver: {s}, activation: {a}, learning rate: {l}\")\n",
    "    cm = m.getCM(pred, testYp)\n",
    "    scores = m.printScore(cm, [s, a, l], False)\n",
    "    modelList.append({\"params\": {\"solver\": s, \"activation\": a, \"learning_rate\": l}, \"cm\": cm, \"scores\": scores})\n",
    "\n",
    "threadlist = []\n",
    "\n",
    "for s in solver:\n",
    "    for a in activation:\n",
    "        for l in learning_rate:\n",
    "            threadlist.append(Thread(target=useModel, args=(s, l, a)))\n",
    "\n",
    "for t in threadlist:\n",
    "    t.start()\n",
    "\n",
    "start = time.time()\n",
    "for i, t in enumerate(threadlist, start=1):\n",
    "    t.join()\n",
    "    print(f\"Done with thread {i}. Used: {round(time.time()-start, 4)} seconds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cm': [[6463, 28], [91, 124]],\n",
      " 'params': {'activation': 'relu',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.68, 'precision': 0.82, 'recall': 0.58}}\n",
      "{'cm': [[6463, 28], [91, 124]],\n",
      " 'params': {'activation': 'relu',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.68, 'precision': 0.82, 'recall': 0.58}}\n",
      "{'cm': [[6463, 28], [91, 124]],\n",
      " 'params': {'activation': 'relu',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.68, 'precision': 0.82, 'recall': 0.58}}\n",
      "{'cm': [[6452, 39], [92, 123]],\n",
      " 'params': {'activation': 'tanh',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.65, 'precision': 0.76, 'recall': 0.57}}\n",
      "{'cm': [[6452, 39], [92, 123]],\n",
      " 'params': {'activation': 'tanh',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.65, 'precision': 0.76, 'recall': 0.57}}\n",
      "{'cm': [[6452, 39], [92, 123]],\n",
      " 'params': {'activation': 'tanh',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.65, 'precision': 0.76, 'recall': 0.57}}\n",
      "{'cm': [[6469, 22], [93, 122]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.68, 'precision': 0.85, 'recall': 0.57}}\n",
      "{'cm': [[6469, 22], [93, 122]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.68, 'precision': 0.85, 'recall': 0.57}}\n",
      "{'cm': [[6469, 22], [93, 122]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.68, 'precision': 0.85, 'recall': 0.57}}\n",
      "{'cm': [[6475, 16], [103, 112]],\n",
      " 'params': {'activation': 'relu',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.65, 'precision': 0.88, 'recall': 0.52}}\n",
      "{'cm': [[6475, 16], [103, 112]],\n",
      " 'params': {'activation': 'relu',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.65, 'precision': 0.88, 'recall': 0.52}}\n",
      "{'cm': [[6475, 16], [103, 112]],\n",
      " 'params': {'activation': 'relu',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.65, 'precision': 0.88, 'recall': 0.52}}\n",
      "{'cm': [[6477, 14], [108, 107]],\n",
      " 'params': {'activation': 'tanh',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.64, 'precision': 0.88, 'recall': 0.5}}\n",
      "{'cm': [[6477, 14], [108, 107]],\n",
      " 'params': {'activation': 'tanh',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.64, 'precision': 0.88, 'recall': 0.5}}\n",
      "{'cm': [[6477, 14], [108, 107]],\n",
      " 'params': {'activation': 'tanh',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.64, 'precision': 0.88, 'recall': 0.5}}\n",
      "{'cm': [[6480, 11], [113, 102]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.62, 'precision': 0.9, 'recall': 0.47}}\n",
      "{'cm': [[6480, 11], [113, 102]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.62, 'precision': 0.9, 'recall': 0.47}}\n",
      "{'cm': [[6480, 11], [113, 102]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.62, 'precision': 0.9, 'recall': 0.47}}\n",
      "{'cm': [[6487, 4], [142, 73]],\n",
      " 'params': {'activation': 'relu', 'learning_rate': 'constant', 'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.5, 'precision': 0.95, 'recall': 0.34}}\n",
      "{'cm': [[6487, 4], [142, 73]],\n",
      " 'params': {'activation': 'relu', 'learning_rate': 'adaptive', 'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.98, 'f1': 0.5, 'precision': 0.95, 'recall': 0.34}}\n",
      "{'cm': [[6486, 5], [163, 52]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.38, 'precision': 0.91, 'recall': 0.24}}\n",
      "{'cm': [[6486, 5], [163, 52]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.38, 'precision': 0.91, 'recall': 0.24}}\n",
      "{'cm': [[6486, 5], [163, 52]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'adam'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.38, 'precision': 0.91, 'recall': 0.24}}\n",
      "{'cm': [[6486, 5], [165, 50]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.37, 'precision': 0.91, 'recall': 0.23}}\n",
      "{'cm': [[6486, 5], [165, 50]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.37, 'precision': 0.91, 'recall': 0.23}}\n",
      "{'cm': [[6486, 5], [165, 50]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'lbfgs'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.37, 'precision': 0.91, 'recall': 0.23}}\n",
      "{'cm': [[6490, 1], [168, 47]],\n",
      " 'params': {'activation': 'tanh', 'learning_rate': 'constant', 'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.36, 'precision': 0.98, 'recall': 0.22}}\n",
      "{'cm': [[6489, 2], [168, 47]],\n",
      " 'params': {'activation': 'tanh', 'learning_rate': 'adaptive', 'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.36, 'precision': 0.96, 'recall': 0.22}}\n",
      "{'cm': [[6489, 2], [169, 46]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.34, 'precision': 0.96, 'recall': 0.21}}\n",
      "{'cm': [[6490, 1], [170, 45]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.35, 'precision': 0.98, 'recall': 0.21}}\n",
      "{'cm': [[6491, 0], [206, 9]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'adaptive',\n",
      "            'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.08, 'precision': 1.0, 'recall': 0.04}}\n",
      "{'cm': [[6491, 0], [207, 8]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'constant',\n",
      "            'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0.08, 'precision': 1.0, 'recall': 0.04}}\n",
      "{'cm': [[6491, 0], [215, 0]],\n",
      " 'params': {'activation': 'logistic',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0, 'precision': 0, 'recall': 0.0}}\n",
      "{'cm': [[6491, 0], [215, 0]],\n",
      " 'params': {'activation': 'identity',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0, 'precision': 0, 'recall': 0.0}}\n",
      "{'cm': [[6491, 0], [215, 0]],\n",
      " 'params': {'activation': 'relu',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0, 'precision': 0, 'recall': 0.0}}\n",
      "{'cm': [[6491, 0], [215, 0]],\n",
      " 'params': {'activation': 'tanh',\n",
      "            'learning_rate': 'invscaling',\n",
      "            'solver': 'sgd'},\n",
      " 'scores': {'accuracy': 0.97, 'f1': 0, 'precision': 0, 'recall': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "sortedModels = sorted(modelList, key=lambda val: (val[\"cm\"][1][1], val[\"scores\"][\"f1\"]), reverse=True)\n",
    "for m in sortedModels:\n",
    "    pp(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afea23f61d6a821af1961b60809105e43be664e14901e921a7e345d902bc2549"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
